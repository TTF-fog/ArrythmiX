{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "cmPe5dqrdOSp",
        "outputId": "e69ae848-a8ad-4a4f-f46c-15e5cd4d4e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'ptb-xl-dataset-reformatted' dataset.\n",
            "Path to dataset files: /kaggle/input/ptb-xl-dataset-reformatted\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'risk_label'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'risk_label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-727844497.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPTBXLRawECGDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_signals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'I'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPTBXLRawECGDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_signals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'I'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPTBXLRawECGDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_signals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'I'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-727844497.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, signals_df, meta_df, lead, seq_len)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0msignal_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignals_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mecgid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ecg_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'risk_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_ecgids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mecgids\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0meid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignals_map\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'risk_label'"
          ]
        }
      ],
      "source": [
        "import torch/\n",
        "        self.signals_df = signals_df\n",
        "        self.meta_df = meta_df\n",
        "        self.lead = lead\n",
        "        self.seq_len = seq_len\n",
        "        self.signals_map = dict()\n",
        "        for ecgid in self.ecgids:\n",
        "            signals = self.signals_df[self.signals_df['ecg_id'] == ecgid]\n",
        "            if signals.empty:\n",
        "                continue\n",
        "            lead_col = f'channel-{ord(lead) - ord(\"I\")}'\n",
        "            signal_arr = signals[lead_col].values\n",
        "            if len(signal_arr) < seq_len:\n",
        "                pad = np.zeros(seq_len)\n",
        "                pad[:len(signal_arr)] = signal_arr\n",
        "                signal_arr = pad\n",
        "            elif len(signal_arr) > seq_len:\n",
        "                signal_arr = signal_arr[:seq_len]\n",
        "            self.signals_map[ecgid] = signal_arr.astype(np.float32)\n",
        "        self.labels_map = meta_df.set_index('ecg_id')['risk_label'].to_dict()\n",
        "        self.valid_ecgids = [eid for eid in self.ecgids if eid in self.signals_map and self.labels_map.get(eid, -1) >= 0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_ecgids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ecgid = self.valid_ecgids[idx]\n",
        "        signal = self.signals_map[ecgid]\n",
        "        label = self.labels_map[ecgid]\n",
        "        return torch.tensor(signal).unsqueeze(0), torch.tensor(label).long()\n",
        "\n",
        "# CNN model for raw ECG inputs\n",
        "class DeepECGClassifier(nn.Module):\n",
        "    def __init__(self, seq_len=5000, num_classes=5):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 32, 15, padding=7)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.conv2 = nn.Conv1d(32, 64, 15, padding=7)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.conv3 = nn.Conv1d(64, 128, 15, padding=7)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.pool3 = nn.MaxPool1d(2)\n",
        "        self.conv4 = nn.Conv1d(128, 256, 15, padding=7)\n",
        "        self.bn4 = nn.BatchNorm1d(256)\n",
        "        self.pool4 = nn.MaxPool1d(2)\n",
        "        def convpool_out_length(l_in, kernel=15, padding=7, pool=2, layers=4):\n",
        "            l = l_in\n",
        "            for _ in range(layers):\n",
        "                l = (l + 2*padding - kernel + 1)\n",
        "                l = l // pool\n",
        "            return l\n",
        "        out_len = convpool_out_length(seq_len)\n",
        "        self.fc1 = nn.Linear(256 * out_len, 128)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "#yes, I daksh vohra used fstrings\n",
        "train_signals = pd.read_csv(f'{path}/train_signal.csv')\n",
        "train_meta = pd.read_csv(f'{path}/train_meta.csv')\n",
        "valid_signals = pd.read_csv(f'{path}/valid_signal.csv')\n",
        "valid_meta = pd.read_csv(f'{path}/valid_meta.csv')\n",
        "test_signals = pd.read_csv(f'{path}/test_signal.csv')\n",
        "test_meta = pd.read_csv(f'{path}/test_meta.csv')\n",
        "\n",
        "\n",
        "train_dataset = PTBXLRawECGDataset(train_signals, train_meta, lead='I', seq_len=5000)\n",
        "valid_dataset = PTBXLRawECGDataset(valid_signals, valid_meta, lead='I', seq_len=5000)\n",
        "test_dataset = PTBXLRawECGDataset(test_signals, test_meta, lead='I', seq_len=5000)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = DeepECGClassifier(seq_len=5000, num_classes=5).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "#useful later\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    total_loss, total_correct, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for signals, labels in loader:\n",
        "            signals, labels = signals.to(device), labels.to(device)\n",
        "            outputs = model(signals)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            predicted = outputs.argmax(dim=1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return total_loss / total if total > 0 else 0, total_correct / total if total > 0 else 0\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss, total_correct, total = 0, 0, 0\n",
        "    for signals, labels in train_loader:\n",
        "        signals, labels = signals.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(signals)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "        predicted = outputs.argmax(dim=1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = total_loss / total\n",
        "    train_acc = total_correct / total\n",
        "    val_loss, val_acc = evaluate(valid_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss {train_loss:.4f}, Train Acc {train_acc:.4f}, Val Loss {val_loss:.4f}, Val Acc {val_acc:.4f}\")\n",
        "\n",
        "test_loss, test_acc = evaluate(test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fe8d145"
      },
      "source": [
        "print(train_meta.columns)\n",
        "print(valid_meta.columns)\n",
        "print(test_meta.columns)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}